{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-serbia",
   "metadata": {
    "id": "opening-serbia"
   },
   "outputs": [],
   "source": [
    "#%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outdoor-rescue",
   "metadata": {
    "id": "outdoor-rescue"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0IiYwiYeQwKi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IiYwiYeQwKi",
    "outputId": "c67eb24c-1dac-4005-f6ac-381fe13308a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4hWIXnIcQ7dS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "4hWIXnIcQ7dS",
    "outputId": "e6638310-aedd-485c-a72d-b489efd448ee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tesla T4'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-alarm",
   "metadata": {
    "id": "systematic-alarm"
   },
   "source": [
    "# Vanilla GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "demographic-anthropology",
   "metadata": {
    "id": "demographic-anthropology"
   },
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    train_data, test_data = 2*(data['train'] / 255) - 1, 2*(data['test']/255)-1\n",
    "    train_labels, test_labels = data['train_labels'], data['test_labels']\n",
    "    return train_data, test_data, train_labels, test_labels\n",
    "\n",
    "\n",
    "def show_samples(samples, title=None, nrow=10):\n",
    "    samples = (torch.FloatTensor(samples.cpu())).permute(0, 3, 1, 2)\n",
    "    grid_img = make_grid(samples, nrow=nrow)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_data(data, title):\n",
    "    idxs = np.random.choice(len(data), replace=False, size=(100,))\n",
    "    images = data[idxs]\n",
    "    show_samples(images, title)\n",
    "    \n",
    "\n",
    "def visualize_batch(batch, nrow=10):\n",
    "    show_samples(batch[...,None], nrow=nrow)\n",
    "\n",
    "\n",
    "def plot_training_curves(train_losses, test_losses):\n",
    "    n_train = len(train_losses[list(train_losses.keys())[0]])\n",
    "    n_test = len(test_losses[list(train_losses.keys())[0]])\n",
    "    x_train = np.linspace(0, n_test - 1, n_train)\n",
    "    x_test = np.arange(n_test)\n",
    "\n",
    "    plt.figure()\n",
    "    for key, value in train_losses.items():\n",
    "        plt.plot(x_train, value, label=key + '_train')\n",
    "\n",
    "    for key, value in test_losses.items():\n",
    "        plt.plot(x_test, value, label=key + '_test')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "varied-maldives",
   "metadata": {
    "id": "varied-maldives"
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = load_pickle('mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LMkCsOu1Z5m0",
   "metadata": {
    "id": "LMkCsOu1Z5m0"
   },
   "outputs": [],
   "source": [
    "visualize_data(train_data, 'MNIST samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "critical-avenue",
   "metadata": {
    "id": "critical-avenue"
   },
   "outputs": [],
   "source": [
    "class VanillaGAN():\n",
    "    def __init__(self, G, D, noise_fn, data_fn,\n",
    "                 batch_size=32, device='cpu', lr_D=1e-3, lr_G=2e-4):\n",
    "        \"\"\"A GAN class for holding and training a generator and discriminator\n",
    "        Args:\n",
    "            G: a Ganerator network\n",
    "            D: A Discriminator network\n",
    "            noise_fn: function f(num: int) -> pytorch tensor, (latent vectors)\n",
    "            data_fn: function f(num: int) -> pytorch tensor, (real samples)\n",
    "            batch_size: training batch size\n",
    "            device: cpu or CUDA\n",
    "            lr_D: learning rate for the discriminator\n",
    "            lr_G: learning rate for the generator\n",
    "        \"\"\"\n",
    "        self.G = G\n",
    "        self.G = self.G.to(device)\n",
    "        self.D = D\n",
    "        self.D = self.D.to(device)\n",
    "        self.noise_fn = noise_fn\n",
    "        self.data_fn = data_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        # !\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optim_D = optim.Adam(D.parameters(),\n",
    "                                  lr=lr_D, betas=(0.5, 0.999))\n",
    "        self.optim_G = optim.Adam(G.parameters(),\n",
    "                                  lr=lr_G, betas=(0.5, 0.999))\n",
    "        # is needed in D train loop\n",
    "        self.target_ones = torch.ones((batch_size, 1)).to(device)\n",
    "        self.target_zeros = torch.zeros((batch_size, 1)).to(device)\n",
    "    \n",
    "    def generate_samples(self, latent_vec=None, num=None):\n",
    "        \"\"\"Sample from the generator.\n",
    "        Args:\n",
    "            latent_vec: A pytorch latent vector or None\n",
    "            num: The number of samples to generate if latent_vec is None\n",
    "        If latent_vec and num are None then us self.batch_size random latent\n",
    "        vectors.\n",
    "        ! We don't need grad for generated samples\n",
    "        \"\"\"\n",
    "        num = self.batch_size if num is None else num\n",
    "        latent_vec = self.noise_fn(num) if latent_vec is None else latent_vec\n",
    "        # your code here\n",
    "        with torch.no_grad():\n",
    "            samples = self.G(latent_vec)\n",
    "        return samples\n",
    "\n",
    "    def train_step_G(self):\n",
    "        \"\"\"Train the generator one step and return the loss.\"\"\"\n",
    "        self.optim_G.zero_grad()\n",
    "        latent_vec = self.noise_fn(self.batch_size)\n",
    "        # your code here\n",
    "        # use self.target_ones\n",
    "        generated = self.G(latent_vec)\n",
    "        classifications = self.D(generated)\n",
    "        loss = self.criterion(classifications, self.target_ones)\n",
    "        loss.backward()\n",
    "        self.optim_G.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def train_step_D(self):\n",
    "        \"\"\"Train the discriminator one step and return the losses.\"\"\"\n",
    "        self.optim_D.zero_grad()\n",
    "\n",
    "        # real samples\n",
    "        real_samples = self.data_fn(self.batch_size)\n",
    "        # calc real loss\n",
    "        # you code here\n",
    "        pred_real = self.D(real_samples)\n",
    "        loss_real = self.criterion(pred_real, self.target_ones)\n",
    "\n",
    "        # generated samples\n",
    "        latent_vec = self.noise_fn(self.batch_size)\n",
    "        # calc fake loss\n",
    "        # you shouldn't optimize G here\n",
    "        # you code here\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake_samples = self.G(latent_vec)\n",
    "        pred_fake = self.D(fake_samples)\n",
    "        loss_fake = self.criterion(pred_fake, self.target_zeros)\n",
    "\n",
    "        # combine\n",
    "        loss = (loss_real + loss_fake) / 2\n",
    "        loss.backward()\n",
    "        self.optim_D.step()\n",
    "        \n",
    "        return loss_real.item(), loss_fake.item()\n",
    "\n",
    "    def train_step(self):\n",
    "        \"\"\"Train both networks and return the losses.\"\"\"\n",
    "        loss_D = self.train_step_D()\n",
    "        loss_G = self.train_step_G()\n",
    "        return loss_G, loss_D\n",
    "    \n",
    "    def generate_images(self, latent_vec=None, num=None):\n",
    "        samples = self.generate_samples(latent_vec=latent_vec, num=num)\n",
    "        return samples.view(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "intermediate-straight",
   "metadata": {
    "id": "intermediate-straight"
   },
   "outputs": [],
   "source": [
    "def visualize_GAN(gan):\n",
    "    sampes = gan.generate_images(num=4)\n",
    "    visualize_batch(sampes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "novel-junior",
   "metadata": {
    "id": "novel-junior"
   },
   "outputs": [],
   "source": [
    "# make data_fn for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hairy-wildlife",
   "metadata": {
    "id": "hairy-wildlife"
   },
   "outputs": [],
   "source": [
    "def loopy(dl):\n",
    "    while True:\n",
    "        for x in iter(dl): yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dependent-fighter",
   "metadata": {
    "id": "dependent-fighter"
   },
   "outputs": [],
   "source": [
    "def get_data_fn(data_loader):\n",
    "    \n",
    "    def data_fn(x):\n",
    "        return next(loopy(data_loader)).cuda()\n",
    "    \n",
    "    return data_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "guided-answer",
   "metadata": {
    "id": "guided-answer"
   },
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_model(hiddens):\n",
    "    assert len(hiddens) > 1\n",
    "\n",
    "    modules = []\n",
    "    for in_, out_ in zip(hiddens[:-2], hiddens[1:-1]):\n",
    "        modules.extend([nn.Linear(in_, out_), nn.ReLU()])\n",
    "\n",
    "    modules.append(nn.Linear(hiddens[-2], hiddens[-1]))\n",
    "\n",
    "    return nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fantastic-pennsylvania",
   "metadata": {
    "id": "fantastic-pennsylvania"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bridal-determination",
   "metadata": {
    "id": "bridal-determination"
   },
   "outputs": [],
   "source": [
    "latent_size = 2\n",
    "noise_fn = lambda x: torch.randn((x,latent_size), device='cuda')\n",
    "train_loader = DataLoader(train_data[...,0].astype(np.float32).reshape(len(train_data), 28*28), batch_size=BATCH_SIZE, shuffle=True)\n",
    "data_fn = get_data_fn(train_loader)\n",
    "\n",
    "gen_hiddens = [latent_size, 16, 32, 128]\n",
    "dis_hiddens = [28*28, 128, 32, 16, 1]\n",
    "G = nn.Sequential(get_simple_model(gen_hiddens), nn.Tanh()).cuda()\n",
    "D = nn.Sequential(*get_simple_model(dis_hiddens), nn.Sigmoid()).cuda()\n",
    "\n",
    "gan = VanillaGAN(G, D, noise_fn, data_fn, batch_size=BATCH_SIZE, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fossil-claim",
   "metadata": {
    "id": "fossil-claim"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCHES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "knowing-dispute",
   "metadata": {
    "id": "knowing-dispute",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_g, loss_d_real, loss_d_fake = [], [], []\n",
    "start = time()\n",
    "for epoch in range(EPOCHS):\n",
    "    #break\n",
    "    loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
    "    for i,batch in enumerate(range(BATCHES)):\n",
    "        lg_, (ldr_, ldf_) = gan.train_step()\n",
    "        \n",
    "        loss_g_running += lg_\n",
    "        loss_d_real_running += ldr_\n",
    "        loss_d_fake_running += ldf_\n",
    "    loss_g.append(loss_g_running / BATCHES)\n",
    "    loss_d_real.append(loss_d_real_running / BATCHES)\n",
    "    loss_d_fake.append(loss_d_fake_running / BATCHES)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} ({int(time() - start)}s):\"\n",
    "          f\" G={loss_g[-1]:.3f},\"\n",
    "          f\" Dr={loss_d_real[-1]:.3f},\"\n",
    "          f\" Df={loss_d_fake[-1]:.3f}\")\n",
    "    visualize_GAN(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D7lr1OGkZmUL",
   "metadata": {
    "id": "D7lr1OGkZmUL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(loss_g, label='G loss')\n",
    "plt.plot(loss_d_real, label='D real')\n",
    "plt.plot(loss_d_fake, label='D fake')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IhTHnLh-Zo2s",
   "metadata": {
    "id": "IhTHnLh-Zo2s"
   },
   "outputs": [],
   "source": [
    "visualize_batch(gan.generate_images(num=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I_8oHXO3Zqcr",
   "metadata": {
    "id": "I_8oHXO3Zqcr"
   },
   "outputs": [],
   "source": [
    "a = 2\n",
    "step = 0.25\n",
    "\n",
    "print('GAN')\n",
    "x, y = np.mgrid[-a:a:step, -a:a:step]\n",
    "pos = np.dstack((x, y))\n",
    "n_row = pos.shape[0]\n",
    "\n",
    "pos = pos.reshape((np.product(pos.shape[:2]), 2))\n",
    "\n",
    "samples = gan.generate_images(torch.from_numpy(pos).float().cuda())\n",
    "\n",
    "visualize_batch(samples, n_row)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "draft_GAN_2_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
