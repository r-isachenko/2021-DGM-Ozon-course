{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opening-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outdoor-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-filing",
   "metadata": {},
   "source": [
    "# Forward KL vs Reverse KL vs JSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recent-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian(mu, sigma):\n",
    "    d = torch.distributions.normal.Normal(mu, sigma)\n",
    "    return lambda X: d.log_prob(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "certain-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_gaussian(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quiet-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.linspace(-10,10,500)).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "statistical-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X.numpy(), p(X).exp().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frequent-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi(x):\n",
    "    # define a mixture of gaussians\n",
    "    k = 0.8\n",
    "    a = get_gaussian(-2, 0.5)\n",
    "    b = get_gaussian(2, 0.5)\n",
    "    \n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "weighted-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X.numpy(), pi(X).exp().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-sample",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-boost",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-throat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southern-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distr(p,pi,X):\n",
    "    with torch.no_grad():\n",
    "        res1 = p(X).exp()\n",
    "        res2 = pi(X).exp()\n",
    "\n",
    "        plt.plot(X.numpy(), res1.numpy(), 'g--', label=r'$p(x)$')\n",
    "        plt.plot(X.numpy(), res2.numpy(), label=r'$\\pi(x)$')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "closing-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distr(p, pi, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-graph",
   "metadata": {},
   "source": [
    "<img src=\"pics/kld_jsd.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "successful-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLD(q,p,X):\n",
    "    # p and q return log pdf\n",
    "    # X - some linspace\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rotary-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSD(q,p,X):\n",
    "    return (KLD(q,p,X) + KLD(p,q,X)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passive-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_start = -1\n",
    "sigma_start = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "approximate-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define trainable params\n",
    "mu = torch.tensor(mu_start, requires_grad=True, dtype=torch.double)\n",
    "sigma = torch.tensor(sigma_start, requires_grad=True, dtype=torch.double)\n",
    "p = get_gaussian(mu, sigma)\n",
    "\n",
    "plot_distr(p, pi, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sonic-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unsigned-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([mu, sigma], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "limiting-colon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # write the train loop for forward KL\n",
    "    print(i)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    plot_distr(p, pi, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "informative-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_KL_dist = [mu.detach().numpy(), sigma.detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-christopher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cooperative-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_KLD_dist = [mu.detach().numpy(), sigma.detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-bride",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSD_dist = [mu.detach().numpy(), sigma.detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tested-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all distr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-alarm",
   "metadata": {},
   "source": [
    "# Vanilla GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-national",
   "metadata": {},
   "source": [
    "<img src=\"pics/gan_objective.jpg\" width=800 height=800 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "tracked-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_model(hiddens):\n",
    "    assert len(hiddens) > 1\n",
    "\n",
    "    modules = []\n",
    "    for in_, out_ in zip(hiddens[:-2], hiddens[1:-1]):\n",
    "        modules.extend([nn.Linear(in_, out_), nn.ReLU()])\n",
    "\n",
    "    modules.append(nn.Linear(hiddens[-2], hiddens[-1]))\n",
    "\n",
    "    return nn.Sequential(*modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "solved-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shallow nn\n",
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "higher-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 2\n",
    "noise_fn = lambda x: torch.rand((x, 1), device='cpu')-2\n",
    "data_fn = lambda x: mu+torch.randn((x, 1), device='cpu')\n",
    "data_pdf = lambda X: norm.pdf(X-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "arranged-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gan_data(data_fn, noise_fn, data_pdf=None):\n",
    "    noise = noise_fn(5000).numpy().flatten()\n",
    "    target = data_fn(5000).numpy().flatten()\n",
    "    \n",
    "    plt.hist(noise, label='noise', alpha=0.5, density=True, color='b')\n",
    "    plt.hist(target, label='target', alpha=0.5, density=True, color='g')\n",
    "    if data_pdf is not None:\n",
    "        x = np.linspace(-6,6,100)\n",
    "        plt.plot(x, data_pdf(x), 'g', label='real distibution')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "phantom-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gan_data(data_fn, noise_fn, data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "critical-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGAN():\n",
    "    def __init__(self, G, D, noise_fn, data_fn,\n",
    "                 batch_size=32, device='cpu', lr_D=1e-3, lr_G=2e-4):\n",
    "        \"\"\"A GAN class for holding and training a generator and discriminator\n",
    "        Args:\n",
    "            G: a Ganerator network\n",
    "            D: A Discriminator network\n",
    "            noise_fn: function f(num: int) -> pytorch tensor, (latent vectors)\n",
    "            data_fn: function f(num: int) -> pytorch tensor, (real samples)\n",
    "            batch_size: training batch size\n",
    "            device: cpu or CUDA\n",
    "            lr_D: learning rate for the discriminator\n",
    "            lr_G: learning rate for the generator\n",
    "        \"\"\"\n",
    "        self.G = G\n",
    "        self.G = self.G.to(device)\n",
    "        self.D = D\n",
    "        self.D = self.D.to(device)\n",
    "        self.noise_fn = noise_fn\n",
    "        self.data_fn = data_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        # !\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optim_D = optim.Adam(D.parameters(),\n",
    "                                  lr=lr_D, betas=(0.5, 0.999))\n",
    "        self.optim_G = optim.Adam(G.parameters(),\n",
    "                                  lr=lr_G, betas=(0.5, 0.999))\n",
    "        # is needed in D train loop\n",
    "        self.target_ones = torch.ones((batch_size, 1)).to(device)\n",
    "        self.target_zeros = torch.zeros((batch_size, 1)).to(device)\n",
    "    \n",
    "    def generate_samples(self, latent_vec=None, num=None):\n",
    "        \"\"\"Sample from the generator.\n",
    "        Args:\n",
    "            latent_vec: A pytorch latent vector or None\n",
    "            num: The number of samples to generate if latent_vec is None\n",
    "        If latent_vec and num are None then us self.batch_size random latent\n",
    "        vectors.\n",
    "        ! We don't need grad for generated samples\n",
    "        \"\"\"\n",
    "        num = self.batch_size if num is None else num\n",
    "        latent_vec = self.noise_fn(num) if latent_vec is None else latent_vec\n",
    "        # your code here\n",
    "        samples = []\n",
    "        \n",
    "        return samples\n",
    "\n",
    "    def train_step_G(self):\n",
    "        \"\"\"Train the generator one step and return the loss.\"\"\"\n",
    "        self.G.zero_grad()\n",
    "        latent_vec = self.noise_fn(self.batch_size)\n",
    "        # your code here\n",
    "        # use self.target_ones\n",
    "        loss = 0\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def train_step_D(self):\n",
    "        \"\"\"Train the discriminator one step and return the losses.\"\"\"\n",
    "        self.D.zero_grad()\n",
    "\n",
    "        # real samples\n",
    "        real_samples = self.data_fn(self.batch_size)\n",
    "        # calc real loss\n",
    "        # you code here\n",
    "        loss_real = 0\n",
    "\n",
    "        # generated samples\n",
    "        latent_vec = self.noise_fn(self.batch_size)\n",
    "        # calc fake loss\n",
    "        # you shouldn't optimize G here\n",
    "        # you code here\n",
    "        \n",
    "        loss_fake = 0\n",
    "\n",
    "        # combine\n",
    "        loss = (loss_real + loss_fake) / 2\n",
    "        loss.backward()\n",
    "        self.optim_D.step()\n",
    "        return loss_real, loss_fake\n",
    "\n",
    "    def train_step(self):\n",
    "        \"\"\"Train both networks and return the losses.\"\"\"\n",
    "        loss_D = self.train_step_D()\n",
    "        loss_G = self.train_step_G()\n",
    "        return loss_G, loss_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fleet-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]\n",
    "G = get_simple_model(gen_hiddens)\n",
    "D = nn.Sequential(*get_simple_model(dis_hiddens), nn.Sigmoid())\n",
    "\n",
    "gan = VanillaGAN(G, D, noise_fn, data_fn, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "intermediate-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_GAN(gan, data_pdf=None):\n",
    "    size = 500\n",
    "    x = np.linspace(-6,6,100)\n",
    "    bins = np.linspace(-6,6,60)\n",
    "    real_data = gan.data_fn(size)\n",
    "    noise = gan.noise_fn(size)\n",
    "    sampled_data = gan.generate_samples(noise)\n",
    "    \n",
    "    plt.hist(noise.numpy(), label='noise', alpha=0.5, density=True, color='b', bins=bins)\n",
    "    plt.hist(real_data.numpy(), label='real data', alpha=0.5, density=True, color='g', bins=bins)\n",
    "    plt.hist(sampled_data.numpy(), label='G samples', alpha=0.5, density=True, color='r', bins=bins)\n",
    "    \n",
    "    if data_pdf is not None:\n",
    "        plt.plot(x, data_pdf(x), 'g', label='real distibution')\n",
    "    with torch.no_grad():\n",
    "        plt.plot(x, gan.D(torch.from_numpy(x).float().unsqueeze(-1)).numpy(), 'b', label='D distibution')\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "silver-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "skilled-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 2\n",
    "noise_fn = lambda x: torch.rand((x, 1), device='cpu')-2\n",
    "data_fn = lambda x: mu+torch.randn((x, 1), device='cpu')\n",
    "data_pdf = lambda X: norm.pdf(X-mu)\n",
    "\n",
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]\n",
    "G = get_simple_model(gen_hiddens)\n",
    "D = nn.Sequential(*get_simple_model(dis_hiddens), nn.Sigmoid())\n",
    "\n",
    "gan = VanillaGAN(G, D, noise_fn, data_fn, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coordinated-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gan_data(data_fn, noise_fn, data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "modular-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fossil-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "knowing-dispute",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step_size = 1\n",
    "loss_g, loss_d_real, loss_d_fake = [], [], []\n",
    "start = time()\n",
    "for epoch in range(epochs):\n",
    "    break\n",
    "    loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
    "    for i,batch in enumerate(range(batches)):\n",
    "        #lg_, (ldr_, ldf_) = gan.train_step()\n",
    "        ldr_, ldf_ = gan.train_step_D()\n",
    "        if i%step_size == 0:\n",
    "            print(i)\n",
    "            print('D train step')\n",
    "            visualize_GAN(gan)\n",
    "        lg_ = gan.train_step_G()\n",
    "        if i%step_size == 0:\n",
    "            print('G train step')\n",
    "            visualize_GAN(gan)\n",
    "        \n",
    "        loss_g_running += lg_\n",
    "        loss_d_real_running += ldr_\n",
    "        loss_d_fake_running += ldf_\n",
    "    loss_g.append(loss_g_running / batches)\n",
    "    loss_d_real.append(loss_d_real_running / batches)\n",
    "    loss_d_fake.append(loss_d_fake_running / batches)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
    "          f\" G={loss_g[-1]:.3f},\"\n",
    "          f\" Dr={loss_d_real[-1]:.3f},\"\n",
    "          f\" Df={loss_d_fake[-1]:.3f}\")\n",
    "    visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "medium-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = 3\n",
    "mu2 = -3\n",
    "k = 0.7\n",
    "\n",
    "noise_fn = lambda x: torch.rand((x, 1), device='cpu') - 0.5\n",
    "\n",
    "def data_fn(x):\n",
    "    a = mu1 + torch.randn((x, 1), device='cpu')\n",
    "    b = mu2 + torch.randn((x, 1), device='cpu')\n",
    "    mask = np.random.rand(x) < k\n",
    "    mask = mask[:, None]\n",
    "    samples = (a * mask + b * (1 - mask))\n",
    "    \n",
    "    return samples.float()\n",
    "\n",
    "data_pdf = lambda X: k*norm.pdf(X-mu1)+(1-k)*norm.pdf(X-mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "young-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gan_data(data_fn, noise_fn, data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "published-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_hiddens = [1,64,64,1]\n",
    "dis_hiddens = [1,64,64,1]\n",
    "G = get_simple_model(gen_hiddens)\n",
    "D = nn.Sequential(*get_simple_model(dis_hiddens), nn.Sigmoid())\n",
    "\n",
    "gan = VanillaGAN(G, D, noise_fn, data_fn, device='cpu')\n",
    "loss_g, loss_d_real, loss_d_fake = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "intelligent-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "associate-glasgow",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "for epoch in range(epochs):\n",
    "    #break\n",
    "    loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
    "    for i,batch in enumerate(range(batches)):\n",
    "        lg_, (ldr_, ldf_) = gan.train_step()\n",
    "        loss_g_running += lg_\n",
    "        loss_d_real_running += ldr_\n",
    "        loss_d_fake_running += ldf_\n",
    "    loss_g.append(loss_g_running / batches)\n",
    "    loss_d_real.append(loss_d_real_running / batches)\n",
    "    loss_d_fake.append(loss_d_fake_running / batches)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} ({int(time() - start)}s):\"\n",
    "          f\" G={loss_g[-1]:.3f},\"\n",
    "          f\" Dr={loss_d_real[-1]:.3f},\"\n",
    "          f\" Df={loss_d_fake[-1]:.3f}\")\n",
    "    visualize_GAN(gan, data_pdf=data_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-disability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
